{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/ianpg/anaconda/envs/AEM_ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/ianpg/anaconda/envs/AEM_ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/ianpg/anaconda/envs/AEM_ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/ianpg/anaconda/envs/AEM_ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/ianpg/anaconda/envs/AEM_ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/ianpg/anaconda/envs/AEM_ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "import keras\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINE_NO</th>\n",
       "      <th>UTMX</th>\n",
       "      <th>UTMY</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>CHANNEL_NO</th>\n",
       "      <th>RX_ALTITUDE</th>\n",
       "      <th>RX_ALTITUDE_STD</th>\n",
       "      <th>TX_ALTITUDE</th>\n",
       "      <th>TX_ALTITUDE_STD</th>\n",
       "      <th>...</th>\n",
       "      <th>DBDT_INUSE_Ch2GT31</th>\n",
       "      <th>DBDT_INUSE_Ch2GT32</th>\n",
       "      <th>DBDT_INUSE_Ch2GT33</th>\n",
       "      <th>DBDT_INUSE_Ch2GT34</th>\n",
       "      <th>DBDT_INUSE_Ch2GT35</th>\n",
       "      <th>DBDT_INUSE_Ch2GT36</th>\n",
       "      <th>DBDT_INUSE_Ch2GT37</th>\n",
       "      <th>closest_pos</th>\n",
       "      <th>closest_ind</th>\n",
       "      <th>VALID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43434.663700</td>\n",
       "      <td>100101</td>\n",
       "      <td>573558.0</td>\n",
       "      <td>4395767.7</td>\n",
       "      <td>63.11</td>\n",
       "      <td>1</td>\n",
       "      <td>49.11</td>\n",
       "      <td>0.060</td>\n",
       "      <td>50.55</td>\n",
       "      <td>0.060</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>12.776932</td>\n",
       "      <td>11198.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43434.663712</td>\n",
       "      <td>100101</td>\n",
       "      <td>573558.5</td>\n",
       "      <td>4395758.1</td>\n",
       "      <td>63.15</td>\n",
       "      <td>2</td>\n",
       "      <td>48.99</td>\n",
       "      <td>0.060</td>\n",
       "      <td>50.82</td>\n",
       "      <td>0.060</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.228002</td>\n",
       "      <td>11198.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43434.663715</td>\n",
       "      <td>100101</td>\n",
       "      <td>573559.3</td>\n",
       "      <td>4395755.2</td>\n",
       "      <td>63.16</td>\n",
       "      <td>1</td>\n",
       "      <td>48.89</td>\n",
       "      <td>0.060</td>\n",
       "      <td>50.76</td>\n",
       "      <td>0.060</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>11198.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43434.663727</td>\n",
       "      <td>100101</td>\n",
       "      <td>573564.0</td>\n",
       "      <td>4395745.9</td>\n",
       "      <td>63.16</td>\n",
       "      <td>2</td>\n",
       "      <td>47.32</td>\n",
       "      <td>0.062</td>\n",
       "      <td>49.20</td>\n",
       "      <td>0.062</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43434.663731</td>\n",
       "      <td>100101</td>\n",
       "      <td>573566.0</td>\n",
       "      <td>4395743.1</td>\n",
       "      <td>63.15</td>\n",
       "      <td>1</td>\n",
       "      <td>46.60</td>\n",
       "      <td>0.063</td>\n",
       "      <td>48.41</td>\n",
       "      <td>0.063</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>3.580503</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7316</th>\n",
       "      <td>43436.748160</td>\n",
       "      <td>710101</td>\n",
       "      <td>579762.1</td>\n",
       "      <td>4390268.5</td>\n",
       "      <td>45.84</td>\n",
       "      <td>1</td>\n",
       "      <td>61.36</td>\n",
       "      <td>0.050</td>\n",
       "      <td>57.98</td>\n",
       "      <td>0.050</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>344.506734</td>\n",
       "      <td>11709.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7317</th>\n",
       "      <td>43436.748172</td>\n",
       "      <td>710101</td>\n",
       "      <td>579763.7</td>\n",
       "      <td>4390244.7</td>\n",
       "      <td>45.84</td>\n",
       "      <td>2</td>\n",
       "      <td>54.92</td>\n",
       "      <td>0.056</td>\n",
       "      <td>51.78</td>\n",
       "      <td>0.056</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>361.668536</td>\n",
       "      <td>11709.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>43436.748176</td>\n",
       "      <td>710101</td>\n",
       "      <td>579764.3</td>\n",
       "      <td>4390237.4</td>\n",
       "      <td>45.84</td>\n",
       "      <td>1</td>\n",
       "      <td>53.01</td>\n",
       "      <td>0.058</td>\n",
       "      <td>50.01</td>\n",
       "      <td>0.058</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>366.785932</td>\n",
       "      <td>11711.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7319</th>\n",
       "      <td>43436.748188</td>\n",
       "      <td>710101</td>\n",
       "      <td>579766.2</td>\n",
       "      <td>4390212.7</td>\n",
       "      <td>45.84</td>\n",
       "      <td>2</td>\n",
       "      <td>47.11</td>\n",
       "      <td>0.065</td>\n",
       "      <td>44.69</td>\n",
       "      <td>0.065</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>384.290957</td>\n",
       "      <td>11711.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7320</th>\n",
       "      <td>43436.748191</td>\n",
       "      <td>710101</td>\n",
       "      <td>579766.9</td>\n",
       "      <td>4390205.1</td>\n",
       "      <td>45.84</td>\n",
       "      <td>1</td>\n",
       "      <td>45.81</td>\n",
       "      <td>0.067</td>\n",
       "      <td>43.48</td>\n",
       "      <td>0.067</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>389.763839</td>\n",
       "      <td>11711.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48032 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TIMESTAMP  LINE_NO      UTMX       UTMY  ELEVATION  CHANNEL_NO  \\\n",
       "0     43434.663700   100101  573558.0  4395767.7      63.11           1   \n",
       "1     43434.663712   100101  573558.5  4395758.1      63.15           2   \n",
       "2     43434.663715   100101  573559.3  4395755.2      63.16           1   \n",
       "3     43434.663727   100101  573564.0  4395745.9      63.16           2   \n",
       "4     43434.663731   100101  573566.0  4395743.1      63.15           1   \n",
       "...            ...      ...       ...        ...        ...         ...   \n",
       "7316  43436.748160   710101  579762.1  4390268.5      45.84           1   \n",
       "7317  43436.748172   710101  579763.7  4390244.7      45.84           2   \n",
       "7318  43436.748176   710101  579764.3  4390237.4      45.84           1   \n",
       "7319  43436.748188   710101  579766.2  4390212.7      45.84           2   \n",
       "7320  43436.748191   710101  579766.9  4390205.1      45.84           1   \n",
       "\n",
       "      RX_ALTITUDE  RX_ALTITUDE_STD  TX_ALTITUDE  TX_ALTITUDE_STD  ...  \\\n",
       "0           49.11            0.060        50.55            0.060  ...   \n",
       "1           48.99            0.060        50.82            0.060  ...   \n",
       "2           48.89            0.060        50.76            0.060  ...   \n",
       "3           47.32            0.062        49.20            0.062  ...   \n",
       "4           46.60            0.063        48.41            0.063  ...   \n",
       "...           ...              ...          ...              ...  ...   \n",
       "7316        61.36            0.050        57.98            0.050  ...   \n",
       "7317        54.92            0.056        51.78            0.056  ...   \n",
       "7318        53.01            0.058        50.01            0.058  ...   \n",
       "7319        47.11            0.065        44.69            0.065  ...   \n",
       "7320        45.81            0.067        43.48            0.067  ...   \n",
       "\n",
       "      DBDT_INUSE_Ch2GT31  DBDT_INUSE_Ch2GT32  DBDT_INUSE_Ch2GT33  \\\n",
       "0                   9999                9999                9999   \n",
       "1                      1                   1                   1   \n",
       "2                   9999                9999                9999   \n",
       "3                      1                   1                   1   \n",
       "4                   9999                9999                9999   \n",
       "...                  ...                 ...                 ...   \n",
       "7316                9999                9999                9999   \n",
       "7317                   0                   0                   0   \n",
       "7318                9999                9999                9999   \n",
       "7319                   0                   0                   0   \n",
       "7320                9999                9999                9999   \n",
       "\n",
       "      DBDT_INUSE_Ch2GT34  DBDT_INUSE_Ch2GT35  DBDT_INUSE_Ch2GT36  \\\n",
       "0                   9999                9999                9999   \n",
       "1                      1                   1                   0   \n",
       "2                   9999                9999                9999   \n",
       "3                      1                   1                   0   \n",
       "4                   9999                9999                9999   \n",
       "...                  ...                 ...                 ...   \n",
       "7316                9999                9999                9999   \n",
       "7317                   0                   0                   0   \n",
       "7318                9999                9999                9999   \n",
       "7319                   0                   0                   0   \n",
       "7320                9999                9999                9999   \n",
       "\n",
       "      DBDT_INUSE_Ch2GT37  closest_pos  closest_ind  VALID  \n",
       "0                   9999    12.776932      11198.0   True  \n",
       "1                      1     3.228002      11198.0   True  \n",
       "2                   9999     0.223607      11198.0   True  \n",
       "3                      1     0.141421      11200.0   True  \n",
       "4                   9999     3.580503      11200.0   True  \n",
       "...                  ...          ...          ...    ...  \n",
       "7316                9999   344.506734      11709.0  False  \n",
       "7317                   1   361.668536      11709.0  False  \n",
       "7318                9999   366.785932      11711.0  False  \n",
       "7319                   1   384.290957      11711.0  False  \n",
       "7320                9999   389.763839      11711.0  False  \n",
       "\n",
       "[48032 rows x 216 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data\n",
    "data = pandas.read_pickle('../raw_processed_data/raw_processed.pkl')\n",
    "dataShort = data.iloc[0:10,19:46].copy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineNumbers=np.unique(data[\"LINE_NO\"])\n",
    "timeDiff=np.diff(data[\"TIMESTAMP\"])\n",
    "timeDiffMask=timeDiff<5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      1\n",
       "2      2\n",
       "3      1\n",
       "4      2\n",
       "      ..\n",
       "705    1\n",
       "706    2\n",
       "707    1\n",
       "708    2\n",
       "709    1\n",
       "Name: CHANNEL_NO, Length: 710, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currData.CHANNEL_NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianpg/anaconda/envs/AEM_ML/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235.0\n"
     ]
    }
   ],
   "source": [
    "# set the number of adjacent soundings to use\n",
    "adSoundings=1;\n",
    "\n",
    "# iterate through the line numbers\n",
    "for line in lineNumbers:\n",
    "\n",
    "    # make a mask for the rows in the big DF that are for this line number\n",
    "    rowIndex=data[\"LINE_NO\"]==line\n",
    "    \n",
    "    # get just the current rows\n",
    "    currData=data.loc[rowIndex,:]\n",
    "    currData.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # make an array of the time differences\n",
    "    timeDiff=np.diff(currData[\"TIMESTAMP\"])\n",
    "\n",
    "    # if the first time difference is large, drop the first row, this throws a warning\n",
    "    if timeDiff[0]>1e-5:\n",
    "        currData.drop([0], inplace=True)\n",
    "        currData.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # set the number of pairs in this line and make some arrays with zeros for the HM and LM data\n",
    "    numberPairs=np.int(len(currData.index)/2)\n",
    "    currDataLM=np.zeros([numberPairs,1+adSoundings*2,37])\n",
    "    currDataHM=np.zeros([numberPairs,1+adSoundings*2,37])\n",
    "    currLabelsLM=np.zeros([numberPairs,1])\n",
    "    currLabelsHM=np.zeros([numberPairs,1])\n",
    "    \n",
    "    # check to see if the first row is LM or HM, set the indexing\n",
    "    if np.mean(currData.loc[0,'DBDT_Ch1GT1':'DBDT_Ch1GT28'])>9990:\n",
    "        hmFirst=1\n",
    "    else:\n",
    "        hmFirst=0\n",
    "        \n",
    "        \n",
    "    # iterate through the number of pairs\n",
    "    for i in range(numberPairs):\n",
    "        if hmFirst==1:\n",
    "            if adSoundings==1:\n",
    "                hmIndex=[(i-1)*2,i*2,(i+1)*2]\n",
    "                lmIndex=[(i-1)*2+1,i*2+1,(i+1)*2+1]\n",
    "            elif adSoundings==2:\n",
    "                hmIndex=[(i-2)*2,(i-1)*2,i*2,(i+1)*2,(i+2)*2]\n",
    "                lmIndex=[(i-2)*2+1,(i-1)*2+1,i*2+1,(i+1)*2+1,(i+2)*2+1]\n",
    "        else:\n",
    "            if adSoundings==1:\n",
    "                lmIndex=[(i-1)*2,i*2,(i+1)*2]\n",
    "                hmIndex=[(i-1)*2+1,i*2+1,(i+1)*2+1]\n",
    "            elif adSoundings==2:\n",
    "                hmIndex=[(i-2)*2,(i-1)*2,i*2,(i+1)*2,(i+2)*2]\n",
    "                lmIndex=[(i-2)*2+1,(i-1)*2+1,i*2+1,(i+1)*2+1,(i+2)*2+1]\n",
    "        \n",
    "        # do something different for the first and last sounding, leave the adjacent sounding as 0s\n",
    "        if i==0:\n",
    "            currDataLM[i,2,0:28]=currData.loc[lmIndex[2],'DBDT_Ch1GT1':'DBDT_Ch1GT28']\n",
    "            currDataHM[i,2,:]=currData.loc[hmIndex[2],'DBDT_Ch2GT1':'DBDT_Ch2GT37']\n",
    "        elif i==numberPairs-1:\n",
    "            currDataLM[i,0,0:28]=currData.loc[lmIndex[0],'DBDT_Ch1GT1':'DBDT_Ch1GT28']\n",
    "            currDataHM[i,0,:]=currData.loc[hmIndex[0],'DBDT_Ch2GT1':'DBDT_Ch2GT37']\n",
    "            \n",
    "        # for the rest fill in both adjacent soundings\n",
    "        else:\n",
    "            currDataLM[i,0,0:28]=currData.loc[lmIndex[0],'DBDT_Ch1GT1':'DBDT_Ch1GT28']\n",
    "            currDataLM[i,2,0:28]=currData.loc[lmIndex[2],'DBDT_Ch1GT1':'DBDT_Ch1GT28']\n",
    "            currDataHM[i,0,:]=currData.loc[hmIndex[0],'DBDT_Ch2GT1':'DBDT_Ch2GT37']\n",
    "            currDataHM[i,2,:]=currData.loc[hmIndex[2],'DBDT_Ch2GT1':'DBDT_Ch2GT37']\n",
    "            \n",
    "        # middle sounding and labels always get set\n",
    "        currDataLM[i,1,0:28]=currData.loc[lmIndex[1],'DBDT_Ch1GT1':'DBDT_Ch1GT28']\n",
    "        currDataHM[i,1,:]=currData.loc[hmIndex[1],'DBDT_Ch2GT1':'DBDT_Ch2GT37']\n",
    "        currLabelsLM[i,0]=currData.loc[i*2+1,'VALID']\n",
    "        currLabelsHM[i,0]=currData.loc[i*2,'VALID']\n",
    "    \n",
    "    if line==lineNumbers[0]:\n",
    "        dataLM=currDataLM\n",
    "        dataHM=currDataHM\n",
    "        labelsLM=currLabelsLM\n",
    "        labelsHM=currLabelsHM\n",
    "    else:\n",
    "        dataLM=np.append(dataLM,currDataLM, axis=0)\n",
    "        dataHM=np.append(dataHM,currDataHM, axis=0)\n",
    "        labelsLM=np.append(labelsLM,currLabelsLM, axis=0)\n",
    "        labelsHM=np.append(labelsHM,currLabelsHM, axis=0)\n",
    "\n",
    "# drop rows where the lm and hm labels dont agree\n",
    "indexGood=labelsHM==labelsLM\n",
    "\n",
    "# see how many locations this happened in\n",
    "print(np.sum(np.abs(labelsLM-labelsHM)))\n",
    "\n",
    "# keep only the rows where they agree\n",
    "dataLM=dataLM[indexGood[:,0],:,:]\n",
    "dataHM=dataHM[indexGood[:,0],:,:]\n",
    "labelsLM=labelsLM[indexGood[:,0],:]\n",
    "labelsHM=labelsHM[indexGood[:,0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23995, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexGood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 20000\n",
      "number of test examples = 3760\n",
      "X_train shape: (20000, 3, 37, 2)\n",
      "Y_train shape: (20000, 1)\n",
      "X_test shape: (3760, 3, 37, 2)\n",
      "Y_test shape: (3760, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianpg/anaconda/envs/AEM_ML/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "indexGood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape):\n",
    "\n",
    "    \"\"\"\n",
    "    input_shape: The height, width and channels as a tuple.  \n",
    "        Note that this does not include the 'batch' as a dimension.\n",
    "        If you have a batch like 'X_train', \n",
    "        then you can provide the input_shape using\n",
    "        X_train.shape[1:]\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (1, 1), strides = (1, 1), name = 'conv0')(X_input)\n",
    "    X = Conv2D(64, (7, 7), strides = (1, 1), name = 'conv1', padding='same')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(100, activation='relu', name='fc0')(X)\n",
    "    X = Dense(50, activation='relu', name='fc1')(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc2')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='HappyModel')\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (1 line)\n",
    "happyModel = model(X_train.shape[1:] )\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: compile the model\n",
    "\n",
    "**Hint**:  \n",
    "Optimizers you can try include `'adam'`, `'sgd'` or others.  See the documentation for [optimizers](https://keras.io/optimizers/)  \n",
    "The \"happiness detection\" is a binary classification problem.  The loss function that you can use is `'binary_cross_entropy'`.  Note that `'categorical_cross_entropy'` won't work with your data set as its formatted, because the data is an array of 0 or 1 rather than two arrays (one for each category).  Documentation for [losses](https://keras.io/losses/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (1 line)\n",
    "adam=keras.optimizers.Adam(beta_1=0.9, beta_2=0.999,lr=0.1)\n",
    "happyModel.compile(optimizer = adam, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: train the model\n",
    "\n",
    "**Hint**:  \n",
    "Use the `'X_train'`, `'Y_train'` variables.  Use integers for the epochs and batch_size\n",
    "\n",
    "**Note**: If you run `fit()` again, the `model` will continue to train with the parameters it has already learned instead of reinitializing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 2s - loss: 0.5926 - acc: 0.7222     \n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 1s - loss: 0.5906 - acc: 0.7232     \n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 1s - loss: 0.5910 - acc: 0.7233     \n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 1s - loss: 0.5909 - acc: 0.7232     \n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 1s - loss: 0.5906 - acc: 0.7232     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a99927390>"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### START CODE HERE ### (1 line)\n",
    "happyModel.fit(x = X_train, y = Y_train, epochs = 5, batch_size = 100)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: evaluate model  \n",
    "**Hint**:  \n",
    "Use the `'X_test'` and `'Y_test'` variables to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3104/3760 [=======================>......] - ETA: 0s\n",
      "Loss = 0.5979559703076139\n",
      "Test Accuracy = 0.714627659574468\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ### (1 line)\n",
    "preds = happyModel.evaluate(x = X_test, y = Y_test)\n",
    "### END CODE HERE ###\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected performance   \n",
    "If your `happyModel()` function worked, its accuracy should be better than random guessing (50% accuracy).\n",
    "\n",
    "To give you a point of comparison, our model gets around **95% test accuracy in 40 epochs** (and 99% train accuracy) with a mini batch size of 16 and \"adam\" optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tips for improving your model\n",
    "\n",
    "If you have not yet achieved a very good accuracy (>= 80%), here are some things tips:\n",
    "\n",
    "- Use blocks of CONV->BATCHNORM->RELU such as:\n",
    "```python\n",
    "X = Conv2D(32, (3, 3), strides = (1, 1), name = 'conv0')(X)\n",
    "X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "X = Activation('relu')(X)\n",
    "```\n",
    "until your height and width dimensions are quite low and your number of channels quite large (≈32 for example).  \n",
    "You can then flatten the volume and use a fully-connected layer.\n",
    "- Use MAXPOOL after such blocks.  It will help you lower the dimension in height and width.\n",
    "- Change your optimizer. We find 'adam' works well. \n",
    "- If you get memory issues, lower your batch_size (e.g. 12 )\n",
    "- Run more epochs until you see the train accuracy no longer improves. \n",
    "\n",
    "**Note**: If you perform hyperparameter tuning on your model, the test set actually becomes a dev set, and your model might end up overfitting to the test (dev) set. Normally, you'll want separate dev and test sets.  The dev set is used for parameter tuning, and the test set is used once to estimate the model's performance in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Conclusion\n",
    "\n",
    "Congratulations, you have created a proof of concept for \"happiness detection\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Points to remember\n",
    "- Keras is a tool we recommend for rapid prototyping. It allows you to quickly try out different model architectures.\n",
    "- Remember The four steps in Keras: \n",
    "\n",
    "\n",
    "1. Create  \n",
    "2. Compile  \n",
    "3. Fit/Train  \n",
    "4. Evaluate/Test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Test with your own image (Optional)\n",
    "\n",
    "Congratulations on finishing this assignment. You can now take a picture of your face and see if it can classify whether your expression is \"happy\" or \"not happy\". To do that:\n",
    "\n",
    "\n",
    "1. Click on \"File\" in the upper bar of this notebook, then click \"Open\" to go on your Coursera Hub.\n",
    "2. Add your image to this Jupyter Notebook's directory, in the \"images\" folder\n",
    "3. Write your image's name in the following code\n",
    "4. Run the code and check if the algorithm is right (0 is not happy, 1 is happy)!\n",
    "    \n",
    "The training/test sets were quite similar; for example, all the pictures were taken against the same background (since a front door camera is always mounted in the same position). This makes the problem easier, but a model trained on this data may or may not work on your own data. But feel free to give it a try! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e6211a048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "img_path = 'images/noahface.jpg'\n",
    "### END CODE HERE ###\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "imshow(img)\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "print(happyModel.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Other useful functions in Keras (Optional)\n",
    "\n",
    "Two other basic features of Keras that you'll find useful are:\n",
    "- `model.summary()`: prints the details of your layers in a table with the sizes of its inputs/outputs\n",
    "- `plot_model()`: plots your graph in a nice layout. You can even save it as \".png\" using SVG() if you'd like to share it on social media ;). It is saved in \"File\" then \"Open...\" in the upper bar of the notebook.\n",
    "\n",
    "Run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 70, 70, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 64, 64, 32)        4736      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool (MaxPooling2D)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 1)                 32769     \n",
      "=================================================================\n",
      "Total params: 37,633\n",
      "Trainable params: 37,569\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "happyModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"556pt\" viewBox=\"0.00 0.00 219.00 556.00\" width=\"219pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-552 215,-552 215,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140180795326648 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140180795326648</title>\n",
       "<polygon fill=\"none\" points=\"43,-511.5 43,-547.5 168,-547.5 168,-511.5 43,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.5\" y=\"-525.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140180795327264 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140180795327264</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 211,-474.5 211,-438.5 0,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.5\" y=\"-452.8\">zero_padding2d_1: ZeroPadding2D</text>\n",
       "</g>\n",
       "<!-- 140180795326648&#45;&gt;140180795327264 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140180795326648-&gt;140180795327264</title>\n",
       "<path d=\"M105.5,-511.313C105.5,-503.289 105.5,-493.547 105.5,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"109,-484.529 105.5,-474.529 102,-484.529 109,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140180795309248 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140180795309248</title>\n",
       "<polygon fill=\"none\" points=\"54,-365.5 54,-401.5 157,-401.5 157,-365.5 54,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.5\" y=\"-379.8\">conv0: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140180795327264&#45;&gt;140180795309248 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140180795327264-&gt;140180795309248</title>\n",
       "<path d=\"M105.5,-438.313C105.5,-430.289 105.5,-420.547 105.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"109,-411.529 105.5,-401.529 102,-411.529 109,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140180795307176 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140180795307176</title>\n",
       "<polygon fill=\"none\" points=\"28,-292.5 28,-328.5 183,-328.5 183,-292.5 28,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.5\" y=\"-306.8\">bn0: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140180795309248&#45;&gt;140180795307176 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140180795309248-&gt;140180795307176</title>\n",
       "<path d=\"M105.5,-365.313C105.5,-357.289 105.5,-347.547 105.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"109,-338.529 105.5,-328.529 102,-338.529 109,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140180795308016 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140180795308016</title>\n",
       "<polygon fill=\"none\" points=\"31.5,-219.5 31.5,-255.5 179.5,-255.5 179.5,-219.5 31.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.5\" y=\"-233.8\">activation_1: Activation</text>\n",
       "</g>\n",
       "<!-- 140180795307176&#45;&gt;140180795308016 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140180795307176-&gt;140180795308016</title>\n",
       "<path d=\"M105.5,-292.313C105.5,-284.289 105.5,-274.547 105.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"109,-265.529 105.5,-255.529 102,-265.529 109,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140180795205784 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140180795205784</title>\n",
       "<polygon fill=\"none\" points=\"24,-146.5 24,-182.5 187,-182.5 187,-146.5 24,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.5\" y=\"-160.8\">max_pool: MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 140180795308016&#45;&gt;140180795205784 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140180795308016-&gt;140180795205784</title>\n",
       "<path d=\"M105.5,-219.313C105.5,-211.289 105.5,-201.547 105.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"109,-192.529 105.5,-182.529 102,-192.529 109,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140180794983424 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140180794983424</title>\n",
       "<polygon fill=\"none\" points=\"50.5,-73.5 50.5,-109.5 160.5,-109.5 160.5,-73.5 50.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.5\" y=\"-87.8\">flatten_1: Flatten</text>\n",
       "</g>\n",
       "<!-- 140180795205784&#45;&gt;140180794983424 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140180795205784-&gt;140180794983424</title>\n",
       "<path d=\"M105.5,-146.313C105.5,-138.289 105.5,-128.547 105.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"109,-119.529 105.5,-109.529 102,-119.529 109,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140180794985720 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140180794985720</title>\n",
       "<polygon fill=\"none\" points=\"71.5,-0.5 71.5,-36.5 139.5,-36.5 139.5,-0.5 71.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.5\" y=\"-14.8\">fc: Dense</text>\n",
       "</g>\n",
       "<!-- 140180794983424&#45;&gt;140180794985720 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140180794983424-&gt;140180794985720</title>\n",
       "<path d=\"M105.5,-73.3129C105.5,-65.2895 105.5,-55.5475 105.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"109,-46.5288 105.5,-36.5288 102,-46.5289 109,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(happyModel, to_file='HappyModel.png')\n",
    "SVG(model_to_dot(happyModel).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AEM_ML]",
   "language": "python",
   "name": "conda-env-AEM_ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
